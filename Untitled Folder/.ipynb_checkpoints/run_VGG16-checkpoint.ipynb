{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MfneNf-gMtL2",
    "outputId": "6ab97ebf-2a39-4a20-f7fc-f5642dbb406f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCreated on Sun Dec 16 18:50:32 2018\\n\\n@author: franck\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Created on Sun Dec 16 18:50:32 2018\n",
    "\n",
    "@author: franck\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tz826-QHPTzT"
   },
   "source": [
    "# Ré-utiliser un modèle de production avec Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y2HEK0V2Pd4M"
   },
   "source": [
    "## Objectif\n",
    "Nous allons voir comment ré-utiliser facilement un modèle de production et entrainé par des spécialistes sur des millions d'images.\n",
    "\n",
    "\n",
    "Ce modèle a été construit par le laboratoire de recherche **Oxford Visual Geometry Group** .\n",
    "Ce modèle a pour nom VGG16.\n",
    "\n",
    "Le modèle VGG a remporté la compétition **ImageNet** ILSVRC \n",
    "\n",
    "(ImageNet Large Scale Visual Recognition Challenge).\n",
    "\n",
    "La compétition réunie chaque année les meilleures laboratoires de recherche sur le sujet et permet de faire avancer l'état de l'art.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1rGm70ulRMLh"
   },
   "source": [
    "## Importer VGG16\n",
    "\n",
    "\n",
    "```\n",
    "from  keras.applications.vgg16 import  VGG16\n",
    "model = VGG16()\n",
    "```\n",
    "\n",
    "Ces instructions provoque le chargement des poids du modèle (528 MB) dans le répertoire :\n",
    "/.keras/models directory\n",
    "\n",
    "Le téléchargement n'a lieu **qu'une** seule fois. Une fois, téléchargés les poids sont ensuite lus depuis le disque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SfIGND83RZoB"
   },
   "outputs": [],
   "source": [
    "from  keras.applications.vgg16 import  VGG16\n",
    "model = VGG16()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k3c8iYvNS63O"
   },
   "source": [
    "## Structure du modèle VGG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8rKQgo_bSUrU"
   },
   "source": [
    "\n",
    "### Exercice : \n",
    "* Observez et commentez la structure du modèle VGG\n",
    "* combien de paramètres le modèle comporte-t-il ?\n",
    "\n",
    "Aide : utilisez la fonction \n",
    "\n",
    "```\n",
    "summary()\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "rp_dT8WJSRso"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a2OVmJ1YTYJ2"
   },
   "source": [
    "Réponse : Le modèle VGG16 comporte environ **140 millions** de paramètres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qlTamI5ZNicS"
   },
   "source": [
    "## Les fichiers avec Google Colab files module\n",
    "text import files ...\n",
    "\n",
    "Vous pourrez sélectionner les fichiers à partir d'une interface graphique. \n",
    "Nous allons importer l'image '05-05-CNN-VGG-mug.jpg'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OPrtgwogNewW"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "dataset = files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hC0mQf8vNBsp"
   },
   "source": [
    "## Préparer l'image au format VGG\n",
    "Les lignes de code prépare l'input (notre image) afin qu'il respecte le format attendu par le modèle VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sY_P5M1GNCLw"
   },
   "outputs": [],
   "source": [
    "from  keras.preprocessing.image import  load_img\n",
    "from  keras.preprocessing.image import  img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# chargement et redimension\n",
    "image = load_img('05-05-CNN-VGG-mug.jpg' , target_size=(224, 224))\n",
    "\n",
    "# convertir NumPy array\n",
    "image = img_to_array(image)\n",
    "\n",
    "# tensor rank 4 (#axis): samples, rows, columns, channels\n",
    "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "\n",
    "# preparation  VGG : soustraire la moyenne des pixels\n",
    "image = preprocess_input(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g8yBUMFeVeMG"
   },
   "source": [
    "## Prédiction avec VGG\n",
    "VGG classifie les images d'entrée parmi **1,000** classes.\n",
    "\n",
    "Il faut demander au modèle d'emettre une probabilité et ensuite extraire la probabilité la plus élévée.\n",
    "Cette probabilité la plus élevée est la classe à laquelle appartient l'objet (du point de vue du modèle)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ghOfWiKKUVB2"
   },
   "outputs": [],
   "source": [
    "#predict()  : probabilite (1,000 types d objet)\n",
    "proba = model.predict(image)\n",
    "\n",
    "# dimension ?\n",
    "print(proba.shape)\n",
    "\n",
    "# le plus grand ?\n",
    "import numpy as np\n",
    "print(\"proba = \" , proba)\n",
    "print(\"position max = \" , np.argmax(proba))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nClIh04lWbme"
   },
   "source": [
    "## Reconnaissance de l'image\n",
    "Il ne reste plus qu'à décoder la prédiction afin d'obtenir le label de l'objet (type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8rgN8b3jWZUy"
   },
   "outputs": [],
   "source": [
    "# interpretation proba\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "# proba -> class label\n",
    "label = decode_predictions(proba)\n",
    "\n",
    "print(\"5 best :\")\n",
    "print(label)\n",
    "\n",
    "print(\"type = \" ,  label[0][0][1])\n",
    "print(\"proba = \" ,  label[0][0][2])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2496_05_05-run-VGG16.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 2",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
